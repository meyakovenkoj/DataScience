---
title: "Lab 5"
author: "Yakovenko Ivan"
date: "11/11/2020"
output:
  html_document:
    df_print: paged
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
if (!require('ggplot2'))
{
  install.packages('ggplot2', dependencies = TRUE)
  library('ggplot2')
}
if (!require('arules'))
{
  install.packages('arules', dependencies = TRUE)
  library('arules')
}
if (!require('arulesViz'))
{
  install.packages('arulesViz', dependencies = TRUE)
  library('arulesViz')
}
```
First we need to load our data. I've used `read.transactions` to read transaction data from csv.
For ‘basket’ format, each line in the transaction data file represents a transaction where the items (item labels) are separated by the characters specified by sep.


```{r}
transact_data <- read.transactions(
        file = "https://hyper.mephi.ru/assets/courseware/v1/4528e593d5d574a075e15cab1da2383b/asset-v1:MEPhIx+CS712DS+2020Fall+type@asset+block/AssociationRules.csv",
        format = "basket",
        sep = " "
)
transact_data
```
# Data Exploration and Rules Inference
## Frequent item table

to find most frequent item we find item with max freq
itemFrequency - For example, it is used to get the single item support from an object of class transactions without mining.

```{r}
freq_tab <- data.frame(itemFrequency(transact_data, type = "absolute"))
freq_tab <- cbind(rownames(freq_tab), freq_tab)
rownames(freq_tab) <- NULL
names(freq_tab) <- c("item","freq")
freq_tab[freq_tab$freq == max(freq_tab$freq),]
```

## Frequent item plot
```{r}
itemFrequencyPlot(transact_data, type="absolute", topN=15)
```

To find max length of transaction:

```{r}
max(size(transact_data))
```

# Rules with apriori

Mine the Association rules with a minimum Support of 1% and a minimum Confidence of 0%.
Mine frequent itemsets, association rules or association hyperedges using the Apriori algorithm. The Apriori algorithm employs level-wise search for frequent itemsets.



```{r}
rules_1 <- apriori(transact_data, parameter = list(supp = 0.01, conf = 0.0, target = "rules"))
cat("For sup=1% & conf=0%: ", length(rules_1), "\n")
```

How many rules are observed when the minimum confidence is 50%.

```{r}
rules_2 <- apriori(transact_data, parameter = list(supp = 0.01, conf = 0.5, target = "rules"))
cat("For sup=1% & conf=50%: ", length(rules_2), "\n")
```


# Rules Vusialization
## Rules Graphical Analysis

Create a scatter plot comparing the parameters support and confidence on the axis, and lift with shading.

Lift measures how many times more often X and Y occur together than expected if they are statisti- cally independent of each other. Lift is a measure [6] of how X and Y are really related rather than coinci- dentally happening together 

```{r}
plot(rules_2, method = "scatterplot", measure = c('support', 'confidence'), shading = 'lift', jitter = 0, engine = "htmlwidget")
```

*Where are the rules located that would be considered interesting and useful?*
High lift & confidence, red and higher points

```{r}
library('plotly')
```

Create a scatter plot measuring support vs. lift; record your observations.

```{r}
plot(rules_2, method = "scatterplot", measure = c('support', 'lift'), shading = 'confidence', jitter = 0, engine = "plotly")
```

*Create a scatter plot measuring support vs. lift; record your observations.*
Red and higher points

##  One downside to the Apriori algorithm, is that extraneous rules can be generated that are not particularly useful.  Identify where these rules are located on the graph.  Explain the relationship between the expected observation of these itemsets and the actual observation of the itemsets.  
With low lift & support, at right bottom of the graph and gray colored

## Three rules


```{r}
rules_3 <- apriori(transact_data, parameter = list(supp = 0.1, conf = 0.0, target = "rules"))
inspect(head(rules_3, n = 3, by='confidence', decreasing = TRUE))
```

If we look at the graph, we notice tree points with `support >= 0.1` and high confidence and lift ~ 1.
Lift = 1 means that this is coincidental rules.

## Coincidental rules
Identify the most interesting rules by extracting the rules in which the Confidence is >0.8. Observe the output of the data table for the most interesting rules.

Sort the rules stating the highest lift first. Provide the 10 rules with the lowest lift. Do they appear to be coincidental (Use lift = 2 as baseline for coincidence)? 

But if we get lift 2 as base we get only 9 values?
```{r, results='hide'}
rules_4 <- apriori(transact_data, parameter = list(supp = 0.01, conf = 0.8, target = "rules"))
tab_rules4 <- inspect(tail(sort(rules_4, by='lift', decreasing = TRUE), n=10))
```


## Matrix
```{r}
plot(rules_4, shading = c('lift', 'confidence'), method = 'matrix')
```

## Identify these rules and explain their appearance. 
Green & pink & red squares => high lift & confidence

## What can you infer about rules represented by a dark blue color?
Lift ~= 1 and high confidence mean that these are coincidental rules.

Extract the three rules with the highest lift.
```{r}
tab_rules4 <- inspect(head(sort(rules_4, by='lift', decreasing = TRUE), n=3))
```

## Graph

```{r}
rules_5 <- apriori(transact_data, parameter = list(supp = 0.01, conf = 0.5, target = "rules"))
rules_graph <- head(rules_5, n = 3, by = 'lift')
inspect(rules_graph)
plot(rules_graph, method = 'graph')
```


## Training and Test Sets

```{r}
training_data <- transact_data[1:8000,]
test_data <- transact_data[8001:10000,]

training_rules <- apriori(training_data, parameter = list(supp = 0.01, conf = 0.1, target = "rules"))
test_rules <- apriori(test_data, parameter = list(supp = 0.01, conf = 0.1, target = "rules"))
```

```{r}
train_dt <- DATAFRAME(intersect(training_rules, test_rules))
test_dt <- DATAFRAME(intersect(test_rules, training_rules))

train_dt
test_dt
```

Training set = 10786 rules
Test set = 12276 rules 
intersect = 8938 rules

So we get means as:

```{r}
#cat('Support test:\t', mean(test_dt$support), '\n')
#cat('Support:\t', mean(train_dt$support), '\n')
#cat('Confidence test:', mean(test_dt$confidence), '\n')
#cat('Confidence:\t', mean(train_dt$confidence))

inspect(head(sort(training_rules, by='lift', decreasing = TRUE), n=100))
```
```{r}
inspect(head(sort(test_rules, by='lift', decreasing = TRUE), n=100))
```


```{r}
inspect(head(sort(intersect(training_rules, test_rules), by='lift', decreasing = TRUE), n=10))
```

Generated rules are correct and work fine on test data. The proof of work is similar mean on different datasets (training and test).
